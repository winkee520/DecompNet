
<!doctype html>
<html lang="en">

<head>
  <meta name="google-site-verification" content="ftFOlJETX-2KNjaPh8W6s8lhigItRuu9fOmjHZZ0nY0" />
  <!-- Required meta tags -->
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <!-- Bootstrap CSS -->
  <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css"
    integrity="sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO" crossorigin="anonymous">

  <title>VisualTTS</title>
</head>
<style type="text/css">
  table {
    width: 100%;
    table-layout: fixed;
  }

  audio {
    width: 100%;
  }

  thead>tr>th:first-child {
    width: 96px;
  }

  @media (max-width: 767px) {
    .big-screen {
      display: none;
    }
  }

  @media (min-width: 767px) {
    .small-screen {
      display: none;
    }
  }
</style>




<body>
  <header class="header">
    <div class="jumbotron bg-secondary text-center">
      <div class="container">
        <div class="row align-items-center">
          <div class="col-md-12">
 
            <h1><a class="text-light">Dual-path minimum-phase and all-pass decomposition network for single channel speech dereverberation </h1><br>   
             <font size=5><span style="color:#FFFFFF"> Xi Liu, Szu-Jui Chen, John H.L. Hansen <br></font>
             <font size=5><span style="color:#FFFFFF">Center for Robust Speech Systems (CRSS), The University of Texas at Dallas, TX, USA <br></font>
		 </a>  
            <p>
              <div class="row">
              </div>
            </p>
            
          </div>
        </div>
      </div>
    </div>
  </header>
  <main>
    <div class="container">
      <div class="row" id="result">
        <div class="col-md-12">
        	<h4>Abstract</h4>  
          With the development of deep neural networks(DNN), many DNN-based speech dereverberation approaches have been proposed to achieve significant improvement over the traditional methods. However, most deep learning-based dereverberation methods solely focus on suppressing time-frequency domain reverberations without utilizing cepstral domain features which are potentially useful for dereverberation. In this paper, we propose a dual-path neural network structure to separately process minimum-phase and all-pass components of single channel speech. Firstly, we decompose speech signal into minimum-phase and all-pass components in cepstral domain, then Conformer embedded U-Net is used to remove reverberations of both components. Finally, we combine these two processed components together to synthesize the enhanced output. The performance of proposed method is tested on REVERB-Challenge evaluation dataset in terms of commonly used objective metrics. Experimental results demonstrate that our method outperforms other compared methods.<br>
<br>
<div style="display: flex; flex-direction: row; justify-content: center; align-items: center;">
  <div style="text-align: center;margin-left: 40px;">
    <img src="cep_decomp.drawio.png" width="600" height="220">
    <p> <br><br>Fig. 1: The schematic workflow: <br>Input noisy speech waveform is decomposed into minimum-phase speech in cepstral domain and all-pass speech in spectral domain, and Conformer UNet is used to separately enhance each part.</p>
  </div>
  <div style="text-align: center; margin-left: 60px;">
    <img src="UNet.drawio.png" width="500" height="150">
    <p> <br>Fig. 2: Model structure of DNNs: 'Confomer U-Net Mini' outputs IRM and 'Conformer U-Net All' outputs real and imaginary spectrum.</p>
  </div>
</div>
<br><br>

      <h4>Test Datasets</h4>
      <b>REVERB-Challenge eval dataset [1]</b>: Public dataset with simulated and real reverberated speech data. <br>

      <br><br>
    <h4> Audio Samples </h4>
    <hr class="hr_line">
    <h5>Simultaed eval dataset</h5>
    <table class="table ">
      <thead>
          <tr>
              <th>Samples</th>
              <th>Orignal</th>
              <th>Clean</th>
              <th>Cepstral branch</th>
              <th>Spectral branch</th>
              <th>Proposed</th>
          </tr>
      </thead>
      <tbody>
        <tr> <td> Sample 1 </td>
          <td><audio controls=""><source src="Original/1.wav"></audio></td>
          <td><audio controls=""><source src="clean/1.wav"></audio></td>
          <td><audio controls=""><source src="cepstral/1.wav"></audio></td>
          <td><audio controls=""><source src="spectral/1.wav"></audio></td>
          <td><audio controls=""><source src="proposed/1.wav"></audio></td>
        </tr>
        <tr> <td> Sample 2 </td>
          <td><audio controls=""><source src="Original/2.wav"></audio></td>
          <td><audio controls=""><source src="clean/2.wav"></audio></td>
          <td><audio controls=""><source src="cepstral/2.wav"></audio></td>
          <td><audio controls=""><source src="spectral/2.wav"></audio></td>
          <td><audio controls=""><source src="proposed/2.wav"></audio></td>
        </tr>
        <tr> <td> Sample 3 </td>
          <td><audio controls=""><source src="Original/3.wav"></audio></td>
          <td><audio controls=""><source src="clean/3.wav"></audio></td>
          <td><audio controls=""><source src="cepstral/3.wav"></audio></td>
          <td><audio controls=""><source src="spectral/3.wav"></audio></td>
          <td><audio controls=""><source src="proposed/3.wav"></audio></td>
        </tr>
        <tr> <td> Sample 4 </td>
          <td><audio controls=""><source src="Original/4.wav"></audio></td>
          <td><audio controls=""><source src="clean/4.wav"></audio></td>
          <td><audio controls=""><source src="cepstral/4.wav"></audio></td>
          <td><audio controls=""><source src="spectral/4.wav"></audio></td>
          <td><audio controls=""><source src="proposed/4.wav"></audio></td>
        </tr>
        <tr> <td> Sample 5 </td>
          <td><audio controls=""><source src="Original/5.wav"></audio></td>
          <td><audio controls=""><source src="clean/5.wav"></audio></td>
          <td><audio controls=""><source src="cepstral/5.wav"></audio></td>
          <td><audio controls=""><source src="spectral/5.wav"></audio></td>
          <td><audio controls=""><source src="proposed/5.wav"></audio></td>
        </tr>
        </tr>
    </tbody>
</table>
<hr class="hr_line">
<h5>Real eval dataset</h5>
<table class="table ">
  <thead>
      <tr>
          <th>Samples</th>
          <th>Orignal</th>
          <th>Cepstral branch</th>
          <th>Spectral branch</th>
          <th>proposed</th>
      </tr>
  </thead>
  <tbody>
    <tr> <td> Sample 1 </td>
      <td><audio controls=""><source src="Original/6.wav"></audio></td>
      <td><audio controls=""><source src="cepstral/6.wav"></audio></td>
      <td><audio controls=""><source src="spectral/6.wav"></audio></td>
      <td><audio controls=""><source src="proposed/6.wav"></audio></td>
    </tr>
    <tr> <td> Sample 2 </td>
      <td><audio controls=""><source src="Original/7.wav"></audio></td>
      <td><audio controls=""><source src="cepstral/7.wav"></audio></td>
      <td><audio controls=""><source src="spectral/7.wav"></audio></td>
      <td><audio controls=""><source src="proposed/7.wav"></audio></td>
    </tr>
    <tr> <td> Sample 3 </td>
      <td><audio controls=""><source src="Original/8.wav"></audio></td>
      <td><audio controls=""><source src="cepstral/8.wav"></audio></td>
      <td><audio controls=""><source src="spectral/8.wav"></audio></td>
      <td><audio controls=""><source src="proposed/8.wav"></audio></td>
    </tr>
    <tr> <td> Sample 4 </td>
      <td><audio controls=""><source src="Original/9.wav"></audio></td>
      <td><audio controls=""><source src="cepstral/9.wav"></audio></td>
      <td><audio controls=""><source src="spectral/9.wav"></audio></td>
      <td><audio controls=""><source src="proposed/9.wav"></audio></td>
    </tr>
    <tr> <td> Sample 5 </td>
      <td><audio controls=""><source src="Original/10.wav"></audio></td>
      <td><audio controls=""><source src="cepstral/10.wav"></audio></td>
      <td><audio controls=""><source src="spectral/10.wav"></audio></td>
      <td><audio controls=""><source src="proposed/10.wav"></audio></td>
    </tr>
    </tr>
</tbody>
</table>
<h4> Spectrogram Samples </h4>
    <hr class="hr_line">
    <img src="test.png" class="container">

<hr class="hr_line">
<h4> References </h4>
[1] Keisuke Kinoshita et al. “The reverb challenge: A common evaluation framework for dereverberation and recognition of reverberant speech,” in 2013 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics, 2013, pp. 1–4 <br>
<br>
        
        
</div>
</div>
